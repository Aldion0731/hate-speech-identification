{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3477a925",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "**This project aims to use a Logistic Regression Classifier along with traditional machine learning feature extraction techniques, to identify hate speech on the Twitter social media platform. It demonstrates the key processes involved in a text cleaning workflow, as well as the use of  some key functions and classes from the nltk library. Wheras a Logistic Regression classifier may not be the best classifier for this type of task, the project helps us to understand the challenges and possible solutions of the class imbalance problem, as well as the need to emphasize particular evaluation metrics over others, in particular problems.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d2cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2778db",
   "metadata": {},
   "source": [
    "### 1. Loading of the tweets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4732a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"TwitterHate.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d2215f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet\n",
       "id                                                          \n",
       "1       0   @user when a father is dysfunctional and is s...\n",
       "2       0  @user @user thanks for #lyft credit i can't us...\n",
       "3       0                                bihday your majesty\n",
       "4       0  #model   i love u take with u all the time in ...\n",
       "5       0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be7a357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c8fe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af5cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)\n",
    "#Only 7% of the tweets have been labelled as hate speech.\n",
    "#Classes are heavily imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ef66a",
   "metadata": {},
   "source": [
    "### 2. Gettin the tweets into a series for easy text cleanup and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc99841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     @user when a father is dysfunctional and is s...\n",
       "2    @user @user thanks for #lyft credit i can't us...\n",
       "3                                  bihday your majesty\n",
       "4    #model   i love u take with u all the time in ...\n",
       "5               factsguide: society now    #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df.tweet\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08c5b6",
   "metadata": {},
   "source": [
    "###  3. Text Cleaning I - removing user handles and URLs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ca8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_remover(tweet):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes a single tweet and removes the user handle from the tweet.\n",
    "    \"\"\"\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    pattern = re.compile(\"@[A_Za-z0-9_]+\")\n",
    "    tweet = pattern.sub(\"\", tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a89bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_remover(tweet):\n",
    "    \"\"\"\n",
    "        This function takes a simgle tweet and replaces any urls within the tweet.\n",
    "    \"\"\"\n",
    "    pattern1 = re.compile(r\"(www\\.\\w+\\.[a-z]+|\\w+\\.com)\")\n",
    "    tweet = pattern1.sub(\"\", tweet)\n",
    "    \n",
    "    \n",
    "        \n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ae81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets1 = tweets.apply(handle_remover).apply(url_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b107db61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1          when a father is dysfunctional and is so sel...\n",
       "2          thanks for #lyft credit i can't use cause th...\n",
       "3                                      bihday your majesty\n",
       "4        #model   i love u take with u all the time in ...\n",
       "5                   factsguide: society now    #motivation\n",
       "                               ...                        \n",
       "31958    ate  isz that youuu?ððððððð...\n",
       "31959      to see nina turner on the airwaves trying to...\n",
       "31960    listening to sad songs on a monday morning otw...\n",
       "31961     #sikh #temple vandalised in in #calgary, #wso...\n",
       "31962                          thank you  for you follow  \n",
       "Name: tweet, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d5753",
   "metadata": {},
   "source": [
    "### 4. Text Cleaning II - tokenization and removal of stopwords, punctuations and redundant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b8e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67997206",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e38a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundancies(tweet):\n",
    "    \"\"\"\n",
    "    This function takes a single tweet, removes stopwords, punctuations, single character words, \n",
    "    non - alphanumeric words, some redundant words as well as the # from hastags.\n",
    "    \"\"\"\n",
    "    tweet = re.sub(r\"#+(\\w+)\", r\"\\1\", tweet) \n",
    "    #This function will remove the #symbols from hashtags while preserving the rest of the term.\n",
    "    s_words = stopwords.words(\"english\")\n",
    "    s_words2 = set(s_words).union(set(punctuation))\n",
    "    s_words2 = s_words2.union({\"rt\", \"amp\"}) \n",
    "    #The above line of code will add the terms \"rt\" and \"amp\" to the list of stopwords.\n",
    "    tokenized_tweet = tt.tokenize(tweet)\n",
    "    tweet1 = [word for word in tokenized_tweet if word not in s_words2 and word.isalnum() and len(word) > 1]\n",
    "    #the code above will remove stopwords, words with non - alphanumeric characters and single character words.\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tweet1\n",
    "\n",
    "\n",
    "\n",
    "clean_tweets2 = cleaned_tweets1.apply(remove_redundancies)\n",
    "\n",
    "   \n",
    "#Differes from word tokenize in that it does not separate hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e3d7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1    [father, dysfunctional, selfish, drags, kids, ...\n",
       "2    [thanks, lyft, credit, use, cause, offer, whee...\n",
       "3                                    [bihday, majesty]\n",
       "4                       [model, love, take, time, urð]\n",
       "5                    [factsguide, society, motivation]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad69a5",
   "metadata": {},
   "source": [
    "### 5.  Getting all words in a single list for word frequency computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11595d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [word for tweet in clean_tweets2 for word in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae03b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241691"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e933b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father',\n",
       " 'dysfunctional',\n",
       " 'selfish',\n",
       " 'drags',\n",
       " 'kids',\n",
       " 'dysfunction',\n",
       " 'run',\n",
       " 'thanks',\n",
       " 'lyft',\n",
       " 'credit',\n",
       " 'use',\n",
       " 'cause',\n",
       " 'offer',\n",
       " 'wheelchair',\n",
       " 'vans',\n",
       " 'pdx',\n",
       " 'disapointed',\n",
       " 'getthanked',\n",
       " 'bihday',\n",
       " 'majesty']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c105f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b560281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'love': 2680, 'day': 2273, 'happy': 1683, 'time': 1128, 'life': 1103, 'like': 1097, 'today': 1008, 'new': 988, 'positive': 929, 'thankful': 920, ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = FreqDist(word_list)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ab78d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2680),\n",
       " ('day', 2273),\n",
       " ('happy', 1683),\n",
       " ('time', 1128),\n",
       " ('life', 1103),\n",
       " ('like', 1097),\n",
       " ('today', 1008),\n",
       " ('new', 988),\n",
       " ('positive', 929),\n",
       " ('thankful', 920)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.most_common(10)\n",
    "#below are the top 10 most commonly used words in the corpus, along with their frequency of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca1186f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.plot(10)\n",
    "#Below is a plot of the frequencies of the top 10 most frequent words in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b83f6",
   "metadata": {},
   "source": [
    "### 6.  Formatting the data for predictive modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d9a3622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1        [father, dysfunctional, selfish, drags, kids, ...\n",
       "2        [thanks, lyft, credit, use, cause, offer, whee...\n",
       "3                                        [bihday, majesty]\n",
       "4                           [model, love, take, time, urð]\n",
       "5                        [factsguide, society, motivation]\n",
       "                               ...                        \n",
       "31958                                    [ate, isz, youuu]\n",
       "31959    [see, nina, turner, airwaves, trying, wrap, ma...\n",
       "31960    [listening, sad, songs, monday, morning, otw, ...\n",
       "31961    [sikh, temple, vandalised, calgary, wso, conde...\n",
       "31962                                      [thank, follow]\n",
       "Name: tweet, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a82b4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_tweets2.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076430e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1    father dysfunctional selfish drags kids dysfun...\n",
       "2    thanks lyft credit use cause offer wheelchair ...\n",
       "3                                       bihday majesty\n",
       "4                             model love take time urð\n",
       "5                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "#Instead of a Series of lists we have a Series of strings.\n",
    "#This can now be operated on by our Feature Extraction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897d997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c72a93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31962 31962\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "556d60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.merge(X, y, left_index=True, right_index=True)\n",
    "final_data = data2[data2.tweet.apply(len) != 0]\n",
    "#This will eliminate all the entries in the series of documents that are empty strings after text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "495df5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988423753206933"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data) / len(data2)\n",
    "#This shows we have retained 99.88% of the data.\n",
    "#1.2 % of the documents resulted in empty strings after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a8f060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model love take time urð</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  label\n",
       "id                                                          \n",
       "1   father dysfunctional selfish drags kids dysfun...      0\n",
       "2   thanks lyft credit use cause offer wheelchair ...      0\n",
       "3                                      bihday majesty      0\n",
       "4                            model love take time urð      0\n",
       "5                       factsguide society motivation      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1eb2b42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929898\n",
       "1    0.070102\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149a483",
   "metadata": {},
   "source": [
    "### 7. Data Splitting and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "036467e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e193d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data.tweet, \n",
    "                                                    final_data.label, stratify=final_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfdfd3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23943,) (23943,) (7982,) (7982,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0871aa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929917\n",
       "1    0.070083\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5376a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929842\n",
       "1    0.070158\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)\n",
    "#The distribution of data in train and test sets are equal. This is very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd2f7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92672961",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ebf0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00ac2822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23943x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 135083 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87e60ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7982x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 43570 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0f9fd",
   "metadata": {},
   "source": [
    "### 8. Model Building and Training (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afee1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eff8074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09919c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6da77b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(train_matrix)\n",
    "test_predictions = clf.predict(test_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "145f3bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22233,    32],\n",
       "       [ 1045,   633]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3406faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550181681493547"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "097c27d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3772348033373063"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c45f41b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5403329065300896"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "037b3fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 96%\n",
      "The recall on the training set is 38%\n",
      "The f1 score on the training set is 54%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the training set is {}%\".format(round(accuracy_score(y_train, train_predictions) * 100)))\n",
    "print(\"The recall on the training set is {}%\".format(round(recall_score(y_train, train_predictions) * 100)))\n",
    "print(\"The f1 score on the training set is {}%\".format(round(f1_score(y_train, train_predictions) * 100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516d871",
   "metadata": {},
   "source": [
    "**Despite the relatively high accuracy (95%), our model does poorly on the training set and is only capable of detecting 37% of the occurences of hate speech within the training set. The model is severely underfitting and is therefore not a good model for the task at hand.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa582408",
   "metadata": {},
   "source": [
    "### 9. Model Building and Training (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f01db539",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3eeb8bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff98e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions2 = clf2.predict(train_matrix)\n",
    "test_predictions2 = clf2.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b25d0fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21077,  1188],\n",
       "       [   36,  1642]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, train_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3caf8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488785866432777"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, train_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8450cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785458879618594"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, train_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b252d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7284826974267968"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, train_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29d53f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5802120141342756"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, train_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0378ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 95%\n",
      "The recall on the training set is 98%\n",
      "The f1 score on the training set is 73%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the training set is {}%\".format(round(accuracy_score(y_train, train_predictions2) * 100)))\n",
    "print(\"The recall on the training set is {}%\".format(round(recall_score(y_train, train_predictions2) * 100)))\n",
    "print(\"The f1 score on the training set is {}%\".format(round(f1_score(y_train, train_predictions2) * 100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74db3d",
   "metadata": {},
   "source": [
    "**This model which attempts to balance out the imbalanced classes, does a much better job at detecting hate speech on the platform. It actually detects 97% of hate speech, significantly more than the 37% detected by the model which did not compensate for the imbalanced classes. This model, however, produces a lot more false postives, that is a lot of non - hate speech is incorrectly being flagged as hate speech. This is evident in the precision score of 58% along with an f1 score (73%) much lower than the recall score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2833695",
   "metadata": {},
   "source": [
    "### Evaluation of Model 2 on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b51e7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9249561513405161"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48f07b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7607142857142857"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, test_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60abf764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4781144781144781"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, test_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca095aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5871812543073742"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38e8061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set is 92%\n",
      "The recall on the test set is 76%\n",
      "The f1 score on the test set is 59%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the test set is {}%\".format(round(accuracy_score(y_test, test_predictions2) * 100)))\n",
    "print(\"The recall on the test set is {}%\".format(round(recall_score(y_test, test_predictions2) * 100)))\n",
    "print(\"The f1 score on the test set is {}%\".format(round(f1_score(y_test, test_predictions2) * 100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e9c9b",
   "metadata": {},
   "source": [
    "**In addition to the high false positive rate mentioned above, Model 2 seems also to overfit to the training set as it is giving much better recall and precision on the training set as opposed to the test set. The recall on the training set is 97% while on the test set it is 78%. This problem is quite significant as it suggests that our model may not generalize well to previously unseen data. We therefore need to tune our hyperparamters and apply some degree of regularization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2527386",
   "metadata": {},
   "source": [
    "### 10. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b55e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e4dac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2884d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = LogisticRegression(max_iter=500, solver=\"liblinear\", class_weight=\"balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1258b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"C\": [0.05, 0.075, 0.1, 0.125], \"penalty\": [\"l2\", \"l1\"] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4e79190",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf3, param_grid=parameters, cv=skf, scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "563c5013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(class_weight='balanced', max_iter=500,\n",
       "                                          solver='liblinear'),\n",
       "             param_grid={'C': [0.05, 0.075, 0.1, 0.125],\n",
       "                         'penalty': ['l2', 'l1']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3cdeda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.125, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_\n",
    "#Despite 0.125 being a terminal value in the parameter values given to C, higher values were not given.\n",
    "#This it because it resulted in a model that did not generalize as well to previously unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80643495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.125, class_weight='balanced', max_iter=500,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_final = gs.best_estimator_\n",
    "clf_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06dc982",
   "metadata": {},
   "source": [
    "### Analysis of the performance of the classifier on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92b95e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions3 = clf_final.predict(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba7ecc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9100119189511323"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, train_predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13896f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20840,  1425],\n",
       "       [  151,  1527]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, train_predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a1cf838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659611231101512"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, train_predictions3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae3f9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 93%\n",
      "The recall on the training set is 91%\n",
      "The f1 score on the training set is 66%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the training set is {}%\".format(round(accuracy_score(y_train, train_predictions3) * 100)))\n",
    "print(\"The recall on the training set is {}%\".format(round(recall_score(y_train, train_predictions3) * 100)))\n",
    "print(\"The f1 score on the training set is {}%\".format(round(f1_score(y_train, train_predictions3) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41976f",
   "metadata": {},
   "source": [
    "### Analysis of the performance of the classifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01125c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions3 = clf_final.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "443db6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678571428571429"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, test_predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9101f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6897,  525],\n",
       "       [ 130,  430]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, test_predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d441806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5676567656765676"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_predictions3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9447a8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.450261780104712"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, test_predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2cf80bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set is 92%\n",
      "The recall on the test set is 77%\n",
      "The f1 score on the test set is 57%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the test set is {}%\".format(round(accuracy_score(y_test, test_predictions3) * 100)))\n",
    "print(\"The recall on the test set is {}%\".format(round(recall_score(y_test, test_predictions3) * 100)))\n",
    "print(\"The f1 score on the test set is {}%\".format(round(f1_score(y_test, test_predictions3) * 100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5b159",
   "metadata": {},
   "source": [
    "### 11. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d913e",
   "metadata": {},
   "source": [
    "**- After cross validation and regularization we have produed a classifier which generalizes slightly better to the test set. We see that the recall on the training set is 0.91 and on the test set is 0.8. These values are closer together than the values of 0.97 and 0.78 that we obtained using the unregularixed model**\n",
    "\n",
    "**- We also see that the model gives f1 scores of 0.66 and 0.57 on the training and test sets respectively. These values are also closer than the f1 score for the training and test sets  (0.73 and 0.58 respectively) seen on the non-regularized model trained without cross validation.**\n",
    "\n",
    "**- This model is significantly better than the unregularized and non - cross validated model for two reasons:**\n",
    "\n",
    "   - first, it gives a slightly higher recall score on the test set (80% compared to 78%). This means it is better at identifying all the occurences of hate speech in previously unseen documents.\n",
    "   - Second, the results on the training and test sets are more similar. This tells us that the model will generalize better to unseen data, thus we can expect to see similar results if the modeled is used in production.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
